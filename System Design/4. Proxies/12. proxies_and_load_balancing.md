**12. PROXIES & LOAD BALANCING PART 1**
------------------------------------------------------------
- a middleman of the internet
- help websites run efficiently, securely, and at scale, handling millions of requests without breaking a sweat.
1. Proxies
    1. Forward Proxies
        - The First Line of Defense.
        - forward proxies are all about protecting the client,
        - acts as a middleman between the user (or client) and the public internet.
        - All your requests to access websites or services first pass through this proxy server.
            * > It checks the requests, possibly alters them, and sends them to destination server on your behalf.
            * > When the server responds, the proxy forwards the response back to you.
        - server which all requests go to first, instead of connecting directly to the internet.
        - Why companies and users love forward proxies:
            1. [Anonymity]:
                - Since the server only sees the proxy’s IP address, your identity stays hidden.
            2. [Content-Filtering]:
                - to block access to certain websites (e.g., YouTube)
                - prevent employees from downloading malicious content.
            3. [Bandwidth-Savings]:
                - can cache content.
                - If multiple users access same data (like a video tutorial), proxy serves a cached copy instead of fetching it every time.
        - How Does a Forward Proxy Work?
            1. You (the client) send a request to access a website.
            2. The request goes to the forward proxy first.
            3. The proxy checks whether the site is allowed, safe, or cached.
            4. If everything is good, the proxy forwards your request to the destination server.
            5. The server responds to the proxy.
            6. The proxy forwards the response back to you.
        - Example in python
            `import http.server`
            `import socketserver`

            `PORT = 8888`

            `class Proxy(http.server.SimpleHTTPRequestHandler):`
                `def do_GET(self):`
                    `# Log the request`
                    `print(f"Request received for {self.path}")`
                    `# Modify the request here if needed, or just forward it as-is`
                    `self.send_response(200)`
                    `self.end_headers()`
                    `self.wfile.write(b"Forward Proxy Response: Request forwarded!")`

            `# Setting up the server to listen on PORT 8888`
            `with socketserver.TCPServer(("", PORT), Proxy) as httpd:`
                `print(f"Serving as a forward proxy on port {PORT}")`
                `httpd.serve_forever()`
    2. Reverse Proxies
        - reverse proxies focus on protecting and optimizing servers.
        - a gatekeeper for your web servers.
            * it ensures that incoming traffic is distributed correctly, securely, and efficiently across multiple servers.
        - What is a Reverse Proxy?
            * positioned between the client (e.g., a browser) and the web server.
            * Instead of having clients connect directly to your web servers, they connect to the reverse proxy.
                * > which then forwards the request to the appropriate server.
                * > This helps with several things:
                    1. [Security]:
                         - can hide your internal servers from direct exposure to the internet.
                         - protecting them from threats like DDoS attacks.
                    2. [Load-Balancing]:
                        - When multiple servers are handling requests, a reverse proxy can distribute the traffic across them.
                        - ensuring no single server gets overwhelmed.
                    3. [Caching]:
                        - can cache static content like images
                        - reducing load times for users and saving bandwidth.
        - How Does a Reverse Proxy Work?
            1. A client sends a request (e.g., visits a website).
            2. Reverse proxy receives the request first.
            3. Reverse proxy decides which server to forward the request to based on traffic, availability, or session info.
            4. Server processes the request and sends the response back to the reverse proxy.
            5. The reverse proxy forwards the response back to the client.
        - Setting Up a Simple Reverse Proxy with NGINX:
            `# NGINX Reverse Proxy Configuration`

            `http {`
                `upstream backend_servers {`
                    `# List of servers to distribute traffic to`
                    `server server1.example.com;`
                    `server server2.example.com;`
                `}`
                ``
                `server {`
                    `listen 80;`
                    ``
                    `# Reverse proxy setup`
                    `location / {`
                        `proxy_pass http://backend_servers;`
                        `proxy_set_header Host $host;`
                        `proxy_set_header X-Real-IP $remote_addr;`
                        `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`
                    `}`
                `}`
            `}`
            * > [upstream] defines a group of backend servers that will handle the traffic.
                * > In this example, requests will be distributed between `server1.example.com` and `server2.example.com.`
            * >  [location] block configures the reverse proxy to forward incoming traffic to the `backend_servers` group.
                * > It also passes headers like the real client’s IP address 
                * > to ensure the backend servers know who made the original request.
    - Difference of a Load Blanacer and Reverse Proxy?
        * When you refer to a load balancer you are referring to a very specific thing
            * >  a server or device that balances inbound requests across two or more web servers to spread the load.
        * A reverse proxy, however, typically has any number of features:
            * > load balancing: as discussed above
            * > [caching]: it can cache content from the web server(s) behind it and thereby reduce the load on the web server(s) and return some static content back to the requester without having to get the data from the web server(s).
            * > [security]: it can protect the web server(s) by preventing direct access from the internet; it might do this through simple means by just obfuscating the web server(s) or it may have some more active components that actually review inbound requests looking for malicious code
            * > [SSL-acceleration]: when SSL is used; it may serve as a termination point for those SSL sessions so that the workload of dealing with the encryption is offloaded from the web server(s)
2. Load Balancers
    - Distributing Traffic for Scalability
    - act as traffic directors, distributing requests across multiple servers so that no single machine is overwhelmed.
    - What is a Load Balancer?
        * > main goal of a load balancer is to prevent any server from being overloaded
        * > provide a seamless experience for users even if one of the servers fails.
    - Load balancers can:
        1. [Distribute-traffic-evenly] among servers (round-robin method).
        2. [Redirect-traffic] to the server that’s least busy (least connections method).
        3. [Detect-server-failures] and reroute traffic to healthy servers.

        * > when you have multiple servers handling traffic for your website, 
        * > the load balancer ensures that no server is overburdened.
        * > provides high availability by rerouting requests if one server goes down.
    - How Does a Load Balancer Work?
        1. A client sends a request to your website.
        2. The request first hits the load balancer.
        3. The load balancer checks which servers are available and least busy.
        4. It then forwards the request to the most appropriate server.
        5. server processes the request and sends the response back to the load balancer.
        6. The load balancer forwards the response back to the client.
    - Types of Load Balancers: Layer 4 vs Layer 7
        1. [Layer-4-Load-Balancers]:
            - work at the transport layer (TCP/UDP). 
            - forward traffic based on IP addresses and port numbers.
            - making them faster but less flexible.
        2. [Layer-7-Load-Balancers]:
            - operate at the application layer (HTTP/HTTPS).
            - They inspect the content of requests (ie headers/cookies/session data) & route traffic based on detailed rules.
            - making them ideal for web applications but with more processing overhead.
    - NGINX as a simple load balancer using the round-robin method:
            `# NGINX Load Balancer Configuration`
            ``
            `http {`
                `upstream backend_servers {`
                    `# List of backend servers to distribute traffic`
                    `server server1.example.com;`
                    `server server2.example.com;`
                    `server server3.example.com;`
                `}`
                ``
                `server {`
                    `listen 80;`
                    ``
                    `# Load balancing setup`
                    `location / {`
                        `proxy_pass http://backend_servers;`
                        `proxy_set_header Host $host;`
                        `proxy_set_header X-Real-IP $remote_addr;`
                        `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`
                    `}`
                `}`
            `}`

        * > [upstream] block defines a group of servers (`server1.example.com`, `server2.example.com`, etc.)
            * > that will share the traffic load.
        * > Requests coming to port 80 are forwarded to one of these backend servers using the round-robin method by default.
        * > This simple setup can handle multiple servers and distribute traffic
            * > making sure that no single server gets overwhelmed.
3. Combining Reverse Proxies and Load Balancers for Robust Architecture
    - Why Use Both Reverse Proxies and Load Balancers?
        * To ensure your site performs well under this load
        * Here’s how it works:
            1. [Load-balancer-at-the-front]: The load balancer sits at the edge of your network, receiving all incoming traffic. Its job is to distribute that traffic across multiple reverse proxies or servers, ensuring that no single machine gets overwhelmed.
            2. [Reverse-proxy-inside-the-network]: After the load balancer directs traffic to a reverse proxy, the reverse proxy forwards the request to the appropriate backend server. This setup ensures that your internal servers are not exposed to the internet and are protected from attacks.
        * How Does This Combination Work?
            1. A [client] sends a request (e.g., loading a webpage or submitting a form).
            2. The [load-balancer] receives the request and routes it to one of several reverse proxies based on traffic or availability.
            3. The [reverse-proxy] takes over and forwards the request to the appropriate backend server, potentially using session data, cookies, or headers to determine the correct server.
            4. The [server] processes the request and sends the response back to the reverse proxy.
            5. The reverse proxy forwards the response back through the load balancer to the client.
        * This layered architecture provides a combination of scalability, security, and efficient traffic management.
    - a simple configuration that combines both a load balancer and reverse proxy using NGINX.
            `http {`
                `upstream reverse_proxies {`
                    `# Load balancer sends traffic to multiple reverse proxies`
                    `server reverse-proxy1.example.com;`
                    `server reverse-proxy2.example.com;`
                `}`
                ``
                `server {`
                    `listen 80;`
                    ``
                    `# Load balancing setup`
                    `location / {`
                        `proxy_pass http://reverse_proxies;`
                        `proxy_set_header Host $host;`
                        `proxy_set_header X-Real-IP $remote_addr;`
                        `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`
                    `}`
                `}`
                ``
                `# Configuration for a reverse proxy`
                `upstream backend_servers {`
                    `# Reverse proxy distributes traffic to backend servers`
                    `server backend1.example.com;`
                    `server backend2.example.com;`
                `}`
                ``
                `server {`
                   `listen 8080;`
                    ``
                    `# Reverse proxy setup`
                    `location / {`
                        `proxy_pass http://backend_servers;`
                        `proxy_set_header Host $host;`
                        `proxy_set_header X-Real-IP $remote_addr;`
                        `proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`
                    `}`
                `}`
            `}`
        * > The first part configures the load balancer to route traffic to one of two reverse proxies.
        * > The second part configures one of those reverse proxies to forward traffic to multiple backend servers.
    - This setup creates a layered architecture where the load balancer distributes traffic between reverse proxies, and the reverse proxies handle internal server traffic.
    - Securing Your Infrastructure: DDoS Protection and SSL Termination
        * > security is as important as scalability and performance.
        * > When you’re handling hundreds or even millions of requests, you also need to protect your servers from malicious attacks and ensure data is transmitted securely.
        * > This is where reverse proxies and load balancers go beyond traffic management to enhance security.
            1. DDoS Protection:
                - A Distributed Denial of Service (DDoS) attack floods your servers with an overwhelming number of requests, often causing downtime. 
                - In a typical scenario, attackers flood a website with traffic, causing it to become inaccessible to legitimate users. This can result in revenue loss, reputational damage, and disrupted services.
                - when you have a reverse proxy or load balancer sitting at the edge of your network, they act as the first line of defense. 
                - Here’s how they help:
                    * > [Traffic-filtering]: 
                        - Load balancers and reverse proxies can filter out malicious traffic before it reaches your internal servers. This could include rate-limiting (restricting the number of requests) or blocking traffic from known malicious IP addresses.
                    * > [Distributed-traffic]: 
                        - By spreading traffic across multiple servers, a load balancer ensures that no single server is overwhelmed by the flood of requests. This helps mitigate the effect of the attack.
                    * > [Auto-scaling]: 
                        - Modern cloud-based load balancers can also automatically spin up new servers during a DDoS attack to handle the additional traffic.
            2. SSL(Secure Sockets Layer) Termination:
                - In the era of data privacy and security regulations, it’s crucial to encrypt traffic between your clients and servers. 
                - SSL ensures that the data exchanged between the client and server is encrypted and secure from eavesdropping. 
                - However, handling SSL encryption and decryption can be resource-intensive for your backend servers.
                - [SSL-termination] 
                    * > allows your reverse proxy or load balancer to handle all the heavy lifting of encrypting and decrypting traffic
                    * > freeing up your backend servers to focus on processing requests. 
                    * > Here’s how it works:
                        1. The client connects to the reverse proxy using HTTPS.
                        2. The reverse proxy terminates the SSL connection, decrypting the data.
                        3. The proxy forwards the decrypted data to your backend servers via an internal, secure network (using HTTP if desired).
                        4. The response from the server is then re-encrypted by the reverse proxy before being sent back to the client.

**12. PROXIES & LOAD BALANCING PART 2**
------------------------------------------------------------
1. Proxies
    1. Forward Proxy
        - Proxy Server that sits in front of clients and after internet.
        - Acts as Guard for internal network
            1. [Access-control]: 
                * Block access to certain websites or restrict internet usage within a company.
            2. [Security]:
                * Scan for any Viruses and block
            3. [Monitoring]:
                * In theory, it could log employees web activity. 
        - Caching responses
            * caches websites a user visits so others on network can get fast access to same website.
    2. Reverse Proxy
        - Proxy Server that sits in front of servers and after internet.
        - Also acts as an intermediary for reuests from clients
            * > primarily serves the server
            * > sitting in front of one or more servers
        - Handles incloming client requests and forwards them to the appropriate servers.
        - Functionality
            1. [Security]:
                - dont want to expose all web servers because it increases attack surface masively.
                - can configure security features on proxy servers.
                - Filter requests for malicious activity before they reach server.
                - Ensure SSL encryption enabled.
            2. [Caching]:
                - speed up responses to clients.
            3. [Logging]:
                - for troubleshooting.
        - Popular Reverse proxies
            * > NGINX
                * > high performance web server
                * > ideal for serving static content
                * > reverse proxy forwarding to appropriate back-end server.
                * > security features like SSL termination.
                * > NGINX handles
                    1. Serving static files and caching of those.
                    2. Load Balancing requests to back-end servers.
                    3. Performing SSL termination.
            * > Ingress for Kubernetes
            * > Load Balance across multiple servers
        - Programming languages with reverse proxy
            * > lightweight proxies
            * > Node Express
                * > a server framework for Node.js
                * > used tp build dynamic web apps and apis by defining routing logic
                * > can cuild custom middleware
            * > load balancing accross multiple CPU cores.
        - Can be used in combination.
        Differences
        ----------------------------------------------------------- 
        |    Forward Proxy            |           Reverse Proxy    |
        -----------------------------------------------------------
        | primarily serves clients    |   primarily serves clients |
        | Used for                    |   Used for                 | 
        |    anonymity                |        load balancing      |
        |    content flitering        |        caching             |
        |    bypasing restrictions    |        SSL termination     |
        |                             |        enhancing security  |
        ------------------------------------------------------------

3. Load Balancer
    - Cloud services have their own load balancers.
    - Have cloud Load Balancer as entry in Public Subnet to your Reverse Proxy and networks in your private subnet.
    - Reverse Proxy has more intelligent routing rules
    - Load balancing routing simple like whos busy.
    - can use SSL Termination.


 




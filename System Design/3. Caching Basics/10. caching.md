**10. CACHING PART 1**
------------------------------------------------------------
- Caching 
    * > is the process of storing copies of frequently accessed data in a temporary, high-speed location to speed up future requests. 
    * > It works by checking the cache first before accessing the slower, original data source, which reduces latency and decreases the load on the original system. 
    * > When the data is found in the cache, it's a "cache hit" and is served immediately. If the data is not in the cache, it's a "cache miss," and the system retrieves it from the original source, stores a copy in the cache, and then serves it.
- How caching works
    1. [Check-the-cache-first]:
        - When a request is made, the system first looks for the data in the cache. 
    2. [Cache-hit]:
        - If the data is in the cache, it is retrieved quickly, and the process is complete.
    3. [Cache-miss]: 
        - If the data is not in the cache, the system fetches it from the original data source, like a database. 
    4. [Store-and-serve]: 
        - The system then stores a copy of this new data in the cache before sending it to the user, making it available for future requests.
- Key concepts
    1. [Cache-hit]: 
        - The requested data is found in the cache. 
    2. [Cache-miss]: 
        - The requested data is not in the cache and must be retrieved from the original source.
    3. [Eviction-policy]: 
        - When a cache is full, a strategy is needed to remove old data to make room for new data. 
        - Common policies include Least Recently Used (LRU), First In First Out (FIFO), and Least Frequently Used (LFU). 
    4. [Synchronization]: 
        - Caches need to be kept consistent with the original data source to avoid serving stale information.
- Types of caching
    1. [Client-side-caching]: 
        - A web browser stores data like images and scripts on a user's device to load pages faster on subsequent visits. 
    2. [Hardware-caching]: 
        - CPUs use small, fast caches (L1, L2, L3) to store frequently used data and instructions, significantly speeding up processing. 
    3. [Server-side-caching]: 
        - Caches are placed between the application and the data source to store the results of database queries or other computations. 
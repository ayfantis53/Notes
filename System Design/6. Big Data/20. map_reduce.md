**20. MAP REDUCE PART 1**
------------------------------------------------------------
- is a programming model for processing large datasets in parallel across a cluster of computers.
- It works by first having a "map" function process chunks of data into intermediate key-value pairs, and then a "reduce" function merges these pairs to produce the final output. 
- This allows for high-speed processing by breaking large tasks into smaller, independent ones that can be executed simultaneously. 
- How it works
    1. `Input`: 
        - The large dataset is split into smaller chunks, typically stored in a distributed file system like HDFS.
    2. `Map`: 
        - A user-defined "map" function is applied to each chunk. 
        - This function processes the input data and generates a set of intermediate key-value pairs.
    3. `Shuffle and Sort`: 
        - The intermediate key-value pairs are then grouped and sorted by their keys.
        - even if they originated from different processing nodes.
    4. `Reduce`: 
        - A "reduce" function is applied to the sorted, grouped pairs. 
        - This function aggregates the values associated with each key to produce the final, consolidated output.
    5. `Output`: 
        - The final result is written back to the distributed file system. 

- Key advantages
    1. `Parallelism`: 
        - It splits large jobs into many small tasks that can run at the same time on different machines, significantly speeding up processing.
    2. `Scalability`: 
        - It is designed to run on clusters of thousands of commodity machines.
        - allowing for horizontal scaling to handle massive amounts of data.
    3. `Fault tolerance`: 
        - The framework automatically handles machine failures.
        - ensuring that the overall job can still complete successfully.
    4. `Simplified programming`: 
        - It allows developers to focus on the logic of the "map" and "reduce" functions without needing to manage the complexities of distributed systems and parallel processing. 